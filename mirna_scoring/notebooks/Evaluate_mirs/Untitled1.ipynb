{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e3e420-3932-4747-98f9-810045624ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def lexicographically_largest_B_1(g_nodes, g_from, g_to):\n",
    "    # Step 1: Build adjacency list\n",
    "    graph = defaultdict(list)\n",
    "    for u, v in zip(g_from, g_to):\n",
    "        graph[u].append(v)\n",
    "        graph[v].append(u)\n",
    "\n",
    "    # Sort adjacency lists in descending order to prioritize larger nodes\n",
    "    for node in graph:\n",
    "        graph[node].sort(reverse=True)\n",
    "\n",
    "    # Step 2: Perform DFS to create traversal order A\n",
    "    A = []\n",
    "    visited = set()\n",
    "\n",
    "    \n",
    "\n",
    "    # Ensure we start from the highest node in the graph\n",
    "    node = max(graph.keys()) if graph else 1  # Default to 1 if graph is empty\n",
    "    stack = [node]\n",
    "    while stack:\n",
    "        curr = stack.pop()\n",
    "        if curr not in visited:\n",
    "            visited.add(curr)\n",
    "            A.append(curr)\n",
    "            # Push neighbors in sorted order (highest first)\n",
    "            for neighbor in graph[curr]:  \n",
    "                if neighbor not in visited:\n",
    "                    stack.append(neighbor)\n",
    "\n",
    "    # Step 3: Construct B from A (preserve first occurrence order)\n",
    "    seen = set()\n",
    "    B = []\n",
    "    for node in A:\n",
    "        if node not in seen:\n",
    "            seen.add(node)\n",
    "            B.append(node)\n",
    "\n",
    "    return B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56aeeb81-8246-4c00-bd85-1e15db206930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 1, 2, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicographically_largest_B(g_nodes = 5, g_from=[1,1,3,3], g_to=[2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bba0a15-c9f3-4961-a030-120b8747ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicographically_largest_B_2(g_nodes, g_from, g_to):\n",
    "    # Step 1: Build adjacency list\n",
    "    graph = {}\n",
    "    for u, v in zip(g_from, g_to):\n",
    "        graph.setdefault(u, []).append(v)\n",
    "        graph.setdefault(v, []).append(u)\n",
    "\n",
    "    # Sort adjacency lists in descending order\n",
    "    for node in graph:\n",
    "        graph[node].sort(reverse=True)\n",
    "\n",
    "    # Step 2: Perform DFS to create traversal order A\n",
    "    A = []\n",
    "    visited = set()\n",
    "    \n",
    "    # Start from the largest node\n",
    "    node = max(graph.keys()) if graph else 1\n",
    "    stack = deque([node])\n",
    "    \n",
    "    while stack:\n",
    "        curr = stack.pop()\n",
    "        if curr in visited:\n",
    "            continue\n",
    "        visited.add(curr)\n",
    "        A.append(curr)\n",
    "        stack.extend(n for n in graph[curr] if n not in visited)\n",
    "\n",
    "    # Step 3: Construct B from A (preserve first occurrence order)\n",
    "    seen = set()\n",
    "    B = [x for x in A if x not in seen and not seen.add(x)]\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c30a14-6cce-4cd1-9788-ef6a8a99047b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g_nodes, \u001b[38;5;28mlist\u001b[39m(g_from), \u001b[38;5;28mlist\u001b[39m(g_to)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Example Usage:\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m g_nodes, g_from, g_to \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_large_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m, in \u001b[0;36mgenerate_large_input\u001b[0;34m(g_nodes, g_edges)\u001b[0m\n\u001b[1;32m     10\u001b[0m     edges\u001b[38;5;241m.\u001b[39mappend((parent, i))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Step 2: Add additional random edges while avoiding duplicates\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mg_edges\u001b[49m:\n\u001b[1;32m     14\u001b[0m     u, v \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, g_nodes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (u, v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m edges \u001b[38;5;129;01mand\u001b[39;00m (v, u) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m edges:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "def generate_large_input(g_nodes, g_edges):\n",
    "    if g_edges < g_nodes - 1:\n",
    "        raise ValueError(\"Number of edges must be at least g_nodes - 1 to ensure connectivity.\")\n",
    "\n",
    "    # Step 1: Create a spanning tree (ensure all nodes are connected)\n",
    "    edges = []\n",
    "    for i in range(2, g_nodes + 1):  # Connect nodes in sequence to ensure connectivity\n",
    "        parent = random.randint(1, i - 1)\n",
    "        edges.append((parent, i))\n",
    "\n",
    "    # Step 2: Add additional random edges while avoiding duplicates\n",
    "    while len(edges) < g_edges:\n",
    "        u, v = random.sample(range(1, g_nodes + 1), 2)\n",
    "        if (u, v) not in edges and (v, u) not in edges:\n",
    "            edges.append((u, v))\n",
    "\n",
    "    # Convert edges to g_from and g_to format\n",
    "    g_from, g_to = zip(*edges)\n",
    "    \n",
    "    return g_nodes, list(g_from), list(g_to)\n",
    "\n",
    "# Example Usage:\n",
    "g_nodes, g_from, g_to = generate_large_input(1000, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76202f12-9007-4bd6-9f95-0800835f8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_function(func, *args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time.perf_counter()\n",
    "    elapsed = end - start\n",
    "    print(f'Time taken: {elapsed:.6f} seconds')\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819dd9e-2068-4e4b-b35f-1eaa84423b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = time_function(lexicographically_largest_B_1, g_nodes, g_from, g_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6082650-fd29-4adb-997e-421382ec97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.002796 seconds\n"
     ]
    }
   ],
   "source": [
    "result_2 = time_function(lexicographically_largest_B_2, g_nodes, g_from, g_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88706bf-50a0-4f37-beb0-3497c47849b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
